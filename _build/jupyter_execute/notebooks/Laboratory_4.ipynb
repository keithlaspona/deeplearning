{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972ba699-16a7-419a-9b7f-1fcc9ccec534",
   "metadata": {},
   "source": [
    "## **Laboratory Task 4 - Training Linear Regression Model in PyTorch**\n",
    "#### **DS Elective 4 - Deep Learning**\n",
    "\n",
    "**Name:** Keith Laspo√±a <br>\n",
    "**Year & Section:** DS4A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e074262",
   "metadata": {},
   "source": [
    "**Instruction:** Train a linear regression model in PyTorch using a regression dataset. Use the following parameters. <br>\n",
    "\n",
    "- Criterion: MSE Loss\n",
    "- Fully Connected Layers x 2\n",
    "- Batch Size: 8\n",
    "- Optimizer: SGD\n",
    "- Epoch: 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20117ccf",
   "metadata": {},
   "source": [
    "![Lab4](../notebooks/images/lab4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095ce93",
   "metadata": {},
   "source": [
    "#### **1. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c584e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7824b5b",
   "metadata": {},
   "source": [
    "#### **2. Define Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec953df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression_data():\n",
    "    # Load dataset\n",
    "    X_raw, y_raw = load_diabetes(return_X_y=True)\n",
    "    y_raw = y_raw.reshape(-1, 1)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler_X = StandardScaler()\n",
    "    X_train = scaler_X.fit_transform(X_train)\n",
    "    X_test = scaler_X.transform(X_test)\n",
    "    \n",
    "    # Scale the target variable (y) to be between 0 and 1\n",
    "    scaler_y = MinMaxScaler()\n",
    "    y_train = scaler_y.fit_transform(y_train)\n",
    "    y_test = scaler_y.transform(y_test)\n",
    "\n",
    "    # Convert to PyTorch\n",
    "    X_train_tensor = torch.from_numpy(X_train).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train).float()\n",
    "    X_test_tensor = torch.from_numpy(X_test).float()\n",
    "    y_test_tensor = torch.from_numpy(y_test).float()\n",
    "\n",
    "    return X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, scaler_X, scaler_y, X_raw.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340faa4a",
   "metadata": {},
   "source": [
    "#### **3. Define Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6c772dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 64),  # First fully connected layer (input size 10, output size 64)\n",
    "    nn.ReLU(),          # Non-linear activation function\n",
    "    nn.Linear(64, 1)    # Second fully connected layer (input size 64, output size 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ebdcd9",
   "metadata": {},
   "source": [
    "#### **4. Define Training Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc3bfb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion: MSE Loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer: SGD\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d5fbb",
   "metadata": {},
   "source": [
    "#### **5. Prepare Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cc74b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and testing data\n",
    "X_train, y_train, X_test, y_test, scaler_X, scaler_y, input_features = create_regression_data()\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f5025",
   "metadata": {},
   "source": [
    "#### **6. Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "165e5935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Training Loss: 0.0002\n",
      "Epoch [200/1000], Training Loss: 0.0018\n",
      "Epoch [300/1000], Training Loss: 0.0012\n",
      "Epoch [400/1000], Training Loss: 0.0275\n",
      "Epoch [500/1000], Training Loss: 0.1258\n",
      "Epoch [600/1000], Training Loss: 0.0209\n",
      "Epoch [700/1000], Training Loss: 0.0214\n",
      "Epoch [800/1000], Training Loss: 0.0489\n",
      "Epoch [900/1000], Training Loss: 0.0003\n",
      "Epoch [1000/1000], Training Loss: 0.1054\n",
      "\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_X, batch_y in train_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"\\nTraining finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a4eb6",
   "metadata": {},
   "source": [
    "#### **7. Evaluate Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8e9426b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "Final Test Loss (on scaled 0-1 data): 0.0251\n",
      "\n",
      "New data points (first 5 features):\n",
      "[[0.49 0.68 0.71 0.83 0.33]\n",
      " [0.45 0.4  0.2  0.47 0.78]\n",
      " [0.77 0.16 0.83 0.26 0.58]\n",
      " [0.35 0.14 0.39 0.07 1.  ]\n",
      " [0.94 0.97 0.06 0.43 0.07]]\n",
      "Model predictions (original scale):\n",
      "[1529.43  282.29  991.9  1048.02 1199.07]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_predictions_scaled = model(X_test)\n",
    "    test_loss = criterion(test_predictions_scaled, y_test)\n",
    "\n",
    "# Convert scaled predictions\n",
    "test_predictions_original = scaler_y.inverse_transform(test_predictions_scaled.numpy())\n",
    "\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Final Test Loss (on scaled 0-1 data): {test_loss.item():.4f}\")\n",
    "\n",
    "new_X = np.random.rand(5, input_features)\n",
    "new_X_scaled = scaler_X.transform(new_X)\n",
    "new_X_tensor = torch.from_numpy(new_X_scaled).float()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions_scaled = model(new_X_tensor)\n",
    "\n",
    "predictions_original = scaler_y.inverse_transform(predictions_scaled.numpy())\n",
    "\n",
    "print(f\"\\nNew data points (first 5 features):\\n{new_X[:, :5].round(2)}\")\n",
    "print(f\"Model predictions (original scale):\\n{predictions_original.flatten().round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e165575",
   "metadata": {},
   "source": [
    "#### **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14792352",
   "metadata": {},
   "source": [
    "This notebook defines a two-layer neural network using PyTorch to predict diabetes progression. A key feature of the code is its preprocessing. The results show this was effective, as the training loop completed with consistently low loss values, and the model achieved a final test loss of approximately **0.0251** on the scaled data. Ultimately, the code demonstrates that after training on normalized data, the model's scaled predictions can be successfully converted back into their original, meaningful range using an inverse transform, as shown in the final evaluation output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4950130",
   "metadata": {},
   "source": [
    "#### **Key Takeaways**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbfab2b",
   "metadata": {},
   "source": [
    "- Data preprocessing is critical for model performance: The activity showed that raw data is rarely used directly. Scaling features with `StandardScaler` and normalizing the target variable with `MinMaxScaler` are essential steps to stabilize the training process and prevent issues like exploding gradients.\n",
    "\n",
    "- PyTorch provides a structured workflow for model training: The entire process followed a clear pattern: defining the model architecture (`nn.Sequential`), setting up the loss function (`nn.MSELoss`) and optimizer (`torch.optim.SGD`), preparing the data with DataLoader, and running the core training loop.\n",
    "\n",
    "- Model outputs must be interpretable: A key lesson was that a model's raw prediction is not always the final answer. Because the target variable was scaled, the model's output also had to be transformed back using `scaler_y.inverse_transform` to be understood in the context of the original problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}