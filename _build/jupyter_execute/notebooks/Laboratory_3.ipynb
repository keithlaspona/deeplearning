{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972ba699-16a7-419a-9b7f-1fcc9ccec534",
   "metadata": {},
   "source": [
    "## **Laboratory Task 3 - Implementing Forward and Backward Propagation**\n",
    "#### **DS Elective 4 - Deep Learning**\n",
    "\n",
    "**Name:** Keith Laspo√±a <br>\n",
    "**Year & Section:** DS4A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e074262",
   "metadata": {},
   "source": [
    "**Instruction:** Perform a forward and backward propagation in python using the inputs from **Laboratory Task 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20117ccf",
   "metadata": {},
   "source": [
    "![Lab2](../notebooks/images/lab3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095ce93",
   "metadata": {},
   "source": [
    "#### **1. Perform standard imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c584e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7824b5b",
   "metadata": {},
   "source": [
    "#### **2. Define activation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec953df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340faa4a",
   "metadata": {},
   "source": [
    "#### **3. Initialize parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6c772dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input vector\n",
    "x = np.array([[1], [0], [1]])\n",
    "\n",
    "# Hidden unit weights\n",
    "hidden_weights = np.array([\n",
    "    [0.2, -0.3],\n",
    "    [0.4,  0.1],\n",
    "    [-0.5, 0.2]\n",
    "])\n",
    "\n",
    "# Output unit weights\n",
    "output_weights = np.array([\n",
    "    [-0.3],\n",
    "    [-0.2]\n",
    "])\n",
    "\n",
    "# Bias\n",
    "hidden_bias = np.array([[-0.4], [0.2]])\n",
    "output_bias = np.array([[0.1]])\n",
    "\n",
    "# True target value\n",
    "target = np.array([[1]])\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ebdcd9",
   "metadata": {},
   "source": [
    "#### **4. Forward Propagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc3bfb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prediction: 0.0800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate hidden layer weighted sum\n",
    "hidden_sum = hidden_weights.T @ x + hidden_bias\n",
    "# Activate hidden layer neurons\n",
    "hidden_output = relu(hidden_sum)\n",
    "\n",
    "# Calculate output layer weighted sum\n",
    "output_sum = output_weights.T @ hidden_output + output_bias\n",
    "# Get final prediction\n",
    "prediction = relu(output_sum)\n",
    "\n",
    "print(f\"Final Prediction: {prediction.flatten()[0]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d5fbb",
   "metadata": {},
   "source": [
    "#### **5. Backward Propagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc74b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta for output layer (delta_output):\n",
      "[[-0.92]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate error derivative\n",
    "error_derivative = -(target - prediction)\n",
    "\n",
    "# Backpropagate to output layer\n",
    "delta_output = error_derivative * relu_derivative(output_sum)\n",
    "print(f\"Delta for output layer (delta_output):\\n{delta_output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf2a988f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of error wrt output weights (d_output_weights):\n",
      "[[ 0.    -0.092]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate derivative of error wrt output weights\n",
    "d_output_weights = delta_output @ hidden_output.T\n",
    "print(f\"Derivative of error wrt output weights (d_output_weights):\\n{d_output_weights}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e85c80f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta for hidden layer (delta_hidden):\n",
      "[[0.   ]\n",
      " [0.184]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Backpropagate to hidden layer\n",
    "delta_hidden = (output_weights @ delta_output) * relu_derivative(hidden_sum)\n",
    "print(f\"Delta for hidden layer (delta_hidden):\\n{delta_hidden}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18186a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of error wrt hidden weights (d_hidden_weights):\n",
      "[[0.    0.    0.   ]\n",
      " [0.184 0.    0.184]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate derivative of error wrt hidden weights\n",
    "d_hidden_weights = delta_hidden @ x.T\n",
    "print(f\"Derivative of error wrt hidden weights (d_hidden_weights):\\n{d_hidden_weights}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99206e11",
   "metadata": {},
   "source": [
    "#### **6. Update Weights and Biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0f1fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Output Weights (output_weights):\n",
      "[[-0.3     ]\n",
      " [-0.199908]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update output layer weights and bias\n",
    "output_weights -= lr * d_output_weights.T\n",
    "output_bias -= lr * delta_output\n",
    "\n",
    "print(f\"Updated Output Weights (output_weights):\\n{output_weights}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7517ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Hidden Weights (hidden_weights):\n",
      "[[ 0.2      -0.300184]\n",
      " [ 0.4       0.1     ]\n",
      " [-0.5       0.199816]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update hidden layer weights and bias\n",
    "hidden_weights -= lr * d_hidden_weights.T\n",
    "hidden_bias -= lr * delta_hidden\n",
    "\n",
    "print(f\"Updated Hidden Weights (hidden_weights):\\n{hidden_weights}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}